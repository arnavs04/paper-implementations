{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T20:44:03.652000Z","iopub.status.busy":"2024-08-06T20:44:03.651603Z","iopub.status.idle":"2024-08-06T20:44:03.657421Z","shell.execute_reply":"2024-08-06T20:44:03.656388Z","shell.execute_reply.started":"2024-08-06T20:44:03.651970Z"},"trusted":true},"outputs":[],"source":["import os\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import torch\n","from torch import nn, optim\n","\n","import torchvision\n","from torchvision import models, transforms\n","from torchvision.utils import save_image\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T20:44:03.659603Z","iopub.status.busy":"2024-08-06T20:44:03.659311Z","iopub.status.idle":"2024-08-06T20:44:03.671064Z","shell.execute_reply":"2024-08-06T20:44:03.670289Z","shell.execute_reply.started":"2024-08-06T20:44:03.659579Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["# Images"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T20:44:03.672402Z","iopub.status.busy":"2024-08-06T20:44:03.672074Z","iopub.status.idle":"2024-08-06T20:44:03.683084Z","shell.execute_reply":"2024-08-06T20:44:03.682205Z","shell.execute_reply.started":"2024-08-06T20:44:03.672371Z"},"trusted":true},"outputs":[],"source":["def load_image(image_name, filepath='../neural-style-transfer/imgs, device='cuda'):\n","    image_path = os.path.join(filepath, image_name + \".jpg\")\n","    image = Image.open(image_path).convert('RGB')\n","    \n","    transform = transforms.Compose([\n","        transforms.Resize(size=(224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","    \n","    image_tensor = transform(image)\n","    image_tensor = image_tensor.unsqueeze(0).to(device)\n","    \n","    return image_tensor"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T20:51:12.528588Z","iopub.status.busy":"2024-08-06T20:51:12.528227Z","iopub.status.idle":"2024-08-06T20:51:12.614593Z","shell.execute_reply":"2024-08-06T20:51:12.613776Z","shell.execute_reply.started":"2024-08-06T20:51:12.528558Z"},"trusted":true},"outputs":[],"source":["original_img = load_image(\"katy-perry\").to(device)\n","style_img = load_image(\"starry-night\").to(device)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T20:51:13.006366Z","iopub.status.busy":"2024-08-06T20:51:13.005495Z","iopub.status.idle":"2024-08-06T20:51:13.010970Z","shell.execute_reply":"2024-08-06T20:51:13.010104Z","shell.execute_reply.started":"2024-08-06T20:51:13.006327Z"},"trusted":true},"outputs":[],"source":["# generated = torch.randn(original_img.data.shape, device=device, requires_grad=True)\n","generated = original_img.clone().detach().requires_grad_(True)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T20:51:13.442314Z","iopub.status.busy":"2024-08-06T20:51:13.441492Z","iopub.status.idle":"2024-08-06T20:51:13.448449Z","shell.execute_reply":"2024-08-06T20:51:13.447534Z","shell.execute_reply.started":"2024-08-06T20:51:13.442276Z"},"trusted":true},"outputs":[],"source":["# Our Layers\n","class VGG(nn.Module):\n","    def __init__(self):\n","        super(VGG, self).__init__()\n","        self.chosen_features = ['0', '5', '10', '19', '28']\n","        self.model = models.vgg19(pretrained = True).features\n","    \n","    def forward(self, x):\n","        features = []\n","        for layer_num, layer in enumerate(self.model):\n","            x = layer(x)\n","            if str(layer_num) in self.chosen_features:\n","                features.append(x)\n","        \n","        return features"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T20:51:13.616666Z","iopub.status.busy":"2024-08-06T20:51:13.616309Z","iopub.status.idle":"2024-08-06T20:51:15.454206Z","shell.execute_reply":"2024-08-06T20:51:15.453177Z","shell.execute_reply.started":"2024-08-06T20:51:13.616639Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["model = VGG().to(device).eval()"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T20:51:15.456150Z","iopub.status.busy":"2024-08-06T20:51:15.455855Z","iopub.status.idle":"2024-08-06T20:55:38.187425Z","shell.execute_reply":"2024-08-06T20:55:38.186502Z","shell.execute_reply.started":"2024-08-06T20:51:15.456125Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 5/6000 [00:01<17:58,  5.56it/s]  "]},{"name":"stdout","output_type":"stream","text":["tensor(328320.1250, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 206/6000 [00:09<04:18, 22.40it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(23416.2461, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 405/6000 [00:18<04:00, 23.22it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(12740.8330, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 606/6000 [00:27<04:00, 22.43it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(8977.0479, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 805/6000 [00:36<03:43, 23.27it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(6990.8081, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1006/6000 [00:44<03:42, 22.47it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(5758.6919, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 1205/6000 [00:53<03:26, 23.23it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(4916.9580, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 1406/6000 [01:02<03:25, 22.40it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(4308.0801, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 1605/6000 [01:10<03:08, 23.26it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(3850.7656, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 1806/6000 [01:19<03:06, 22.44it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(3495.1389, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2005/6000 [01:28<02:52, 23.21it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(3209.9231, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 2206/6000 [01:37<02:49, 22.42it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(2976.1528, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 2405/6000 [01:45<02:34, 23.25it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(2780.1489, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 2606/6000 [01:54<02:31, 22.41it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(2611.4976, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 47%|████▋     | 2805/6000 [02:03<02:17, 23.26it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(2464.3345, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3006/6000 [02:12<02:13, 22.40it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(2332.5945, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 53%|█████▎    | 3205/6000 [02:20<02:00, 23.20it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(2212.3938, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 3406/6000 [02:29<01:55, 22.37it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(2100.9805, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 3605/6000 [02:38<01:43, 23.19it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1996.9719, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 3806/6000 [02:46<01:37, 22.41it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1898.9210, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4005/6000 [02:55<01:25, 23.22it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1804.8837, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 4206/6000 [03:04<01:20, 22.39it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1713.8743, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 4405/6000 [03:13<01:08, 23.15it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1625.7507, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 4606/6000 [03:21<01:02, 22.31it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1539.9393, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 4805/6000 [03:30<00:51, 23.18it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1456.6022, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5006/6000 [03:39<00:44, 22.35it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1375.7684, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 5205/6000 [03:48<00:34, 23.13it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1297.0745, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 5406/6000 [03:56<00:26, 22.34it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1220.5159, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 5605/6000 [04:05<00:17, 23.09it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1146.7263, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":[" 97%|█████████▋| 5806/6000 [04:14<00:08, 22.31it/s]"]},{"name":"stdout","output_type":"stream","text":["tensor(1074.8008, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6000/6000 [04:22<00:00, 22.84it/s]\n"]}],"source":["# Hyperparameters\n","epochs = 6000\n","learning_rate = 0.001\n","alpha = 1\n","beta = 0.01\n","optimizer = optim.Adam([generated], lr=learning_rate)\n","\n","for step in tqdm(range(epochs)):\n","    # Obtain the convolution features in specifically chosen layers\n","    generated_features = model(generated)\n","    original_img_features = model(original_img)\n","    style_features = model(style_img)\n","\n","    # Loss is 0 initially\n","    style_loss = original_loss = 0\n","\n","    # iterate through all the features for the chosen layers\n","    for gen_feature, orig_feature, style_feature in zip(\n","        generated_features, original_img_features, style_features\n","    ):\n","\n","        # batch_size will just be 1\n","        batch_size, channel, height, width = gen_feature.shape\n","        original_loss += torch.mean((gen_feature - orig_feature) ** 2)\n","        # Compute Gram Matrix of generated\n","        G = gen_feature.view(channel, height * width).mm(\n","            gen_feature.view(channel, height * width).t()\n","        )\n","        # Compute Gram Matrix of Style\n","        A = style_feature.view(channel, height * width).mm(\n","            style_feature.view(channel, height * width).t()\n","        )\n","        style_loss += torch.mean((G - A) ** 2)\n","\n","    total_loss = alpha * original_loss + beta * style_loss\n","    optimizer.zero_grad()\n","    total_loss.backward()\n","    optimizer.step()\n","\n","    if step % 200 == 0:\n","        print(total_loss)\n","        save_image(generated, \"generated.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5505445,"sourceId":9120188,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
